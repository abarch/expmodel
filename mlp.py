import sys
import optparse
import os
import numpy as np
from compiler.ast import flatten

#sklearn imports
from sklearn import preprocessing
from sklearn.cross_validation import train_test_split   

#local imports 
from features import parseFile
#from features import composeFeatures 


#keras imports 
from keras.models import Sequential
from keras.layers.core import Dense, Activation

NB_CLASSES=16

class Evaluation:

    def __init__(self, X_test, Y_test, prediction, learn):
        # input variables 
        self.x = X_test
        self.y = Y_test
        self.p = prediction
        self.learn = learn

        self.r = NB_CLASSES
        
        self.ratio = np.zeros([len(learn), NB_CLASSES])
        self.correct = np.zeros([len(learn), NB_CLASSES])
        self.classdistr = np.zeros([len(learn), NB_CLASSES])
        

    # find first max index in a list of outputs generated by NN     
    def firstmax_index (self, ll):
        return ll.index(max(ll))
        
    # find second max index in a list of outputs generated by NN
    def secondmax_index (self, ll):
        s =  sorted(ll, reverse=True)
        return ll.index(s[1])

    # label: simple label 
    def extract_class(self, label):
        return label.index(max(label))
    # pred: prediction in range[0:1]    
    def extract_class_max(self, pred):
        return self.firstmax_index(pred)
        
    def labelstats (self, label, pred):
        res = np.zeros([len(self.learn), NB_CLASSES])
        for i in range(len(self.learn)):
            l = list(label[i*self.r:(i+1)*self.r])
            
            self.classdistr[i] += l
            
            p = list(pred[i*self.r:(i+1)*self.r])

            class_label= self.extract_class(l)
            class_prediction = self.extract_class_max(p)
            # print class_label, class_prediction
            res[i, class_label] = 1.0 if class_label == class_prediction else 0
        #print res
        return res
                                                    
    def stats(self):
        overall=len(self.x)
        
        for i in range(overall):
            res = self.labelstats(self.y[i],self.p[i])
            self.correct= np.add(self.correct, res) 
        self.ratio = np.divide(self.correct, self.classdistr)     
        self.print_stat()

    def print_stat(self):
        print "classdistribution ", self.classdistr 
        print "correct ", self.correct
        print "ratio ", self.ratio
        

# finger 1,2,3,4,5
class Features:

    def __init__(self, distances, fingers, hand, labels, learn):
        self.distances = distances
        self.fingers = fingers
        self.hand = hand
        self.labels = labels
        self.learn = learn


    def empty(self, featurevec):
        if ('' in featurevec ) or (' ' in featurevec):
            return True
    def equal_ts(self, tss): 
        tss= map (int, tss)
        return all(x==tss[0] for x in tss)
    def get_ts(self, vec):
        return vec[0]
    def get_feature(self, vec):
        return vec[1]

    def contains_class(self, c, label):
        for i in self.learn:
            if label[i-1]==c: 
                return True
        return False
            
        
        
    def labelFingers(self, label):
        nb_labels = NB_CLASSES
        nb_fingers = len(self.learn)
        zeros = np.zeros([nb_fingers, nb_labels])
        
        for i in range(nb_fingers): 
            zeros[i, label[self.learn[i]-1]]=1

        return zeros.flatten().tolist()

    def composeFeatures (self):
        alldata=[]
        labeling=[]
        unpr= len(distances)
        print "complete data length", unpr
        for i  in range(unpr):

            di=distances[i]
            vfi=fingers[i]
            vhi=hand[i]
            labeli = labels[i]
            assert self.equal_ts(map(self.get_ts, [vfi,vhi, labeli]))

            labeli= self.get_feature(labeli)
            labeli = map( int, labeli)

            
            features= map (self.get_feature, [di, vfi,vhi])
            
            if not (True in  map (self.empty, features)) and \
               not (self.contains_class(0, labeli)) and \
               not (self.contains_class(15, labeli)):
                features= flatten (features)
                labeli = self.labelFingers(labeli)
                labeling += [labeli]
                alldata +=[map(float, features)]
                
    
        X = np.array(alldata)
        Y = np.array(labeling)

        return X,Y 


if __name__ == "__main__":
    parser = optparse.OptionParser(usage = 'usage: %prog [OPTIONS]')
    parser.add_option('--handv-file', 
                      dest    = 'handv_file',
                      default = 'handvelocity.txt')
    parser.add_option('--fingerv-file', 
                      dest    = 'fingerv_file',
                      default = 'fingervelocity.txt')
    parser.add_option('--distance-file', 
                      dest    = 'distance_file',
                      default = 'smootheddistances.txt')
    parser.add_option('--board-annotation-file',
                      dest = 'board_annotation_file',
                      default = 'annotation2D.txt')
    parser.add_option('--label-annotation-file',
                      dest = 'label_annotation_file',
                      default = 'labels.csv')
    parser.add_option('--input-dir',
                      dest  = 'input_dir',
                      default = '/homes/abarch/hapticexp/code/expmodel/featuredata')
    parser.add_option('--nb-epoches', 
                      dest = 'nb_epoches',
                      type = "int",
                      default = 1)
    parser.add_option('--hidden-units',
                      dest = 'hidden_units',
                      type = "int",
                      default = 500) 
    parser.add_option('--learn-fingers',
                      dest = "learn_fingers",
                      default = '1 2 3 4 5')
    (options, args) = parser.parse_args(sys.argv)
    
    # data extraction parameters  
    board = [1,1]



    # reading data from files
    board_annotation_file=os.path.join(options.input_dir, 
                                       options.board_annotation_file)
    distances= parseFile(os.path.join(options.input_dir, 
                                      options.distance_file),  
                         board_annotation_file, board, range(2,12)) 
    fingers= parseFile(os.path.join(options.input_dir, 
                                    options.fingerv_file), 
                       board_annotation_file, board, range(1,11))
    hand =  parseFile(os.path.join(options.input_dir, options.handv_file), 
                      board_annotation_file, board, range(1,4))
    labels = parseFile(os.path.join(options.input_dir, 
                                    options.label_annotation_file), 
                       board_annotation_file, board, range(2, 7))

    learn = options.learn_fingers
    learn = [int(x) for x in list(learn)
             if x!=' ']
    
    # put data togeather with its labels
    features = Features(distances,fingers, hand, labels, learn)
    X,Y = features.composeFeatures()

    print X.shape
    print Y.shape
    
    

    #preprocessing
    #scaler to 1 variance
    scaler = preprocessing.StandardScaler()
    X=scaler.fit_transform(X)

    
    test_size = 0.2
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, 
                                                        test_size=test_size,
                                                        random_state=0)
        
    verbose = 0 
    batch_size =  32
    nb_epoch=options.nb_epoches
    dim_input = X.shape[1]
    dim_output = Y.shape[1]
    hidden_layer = options.hidden_units 
                    

    model = Sequential()          
    model.add(Dense(input_dim=dim_input, output_dim=hidden_layer))
    model.add(Activation("sigmoid"))
    model.add(Dense(input_dim=hidden_layer, output_dim=dim_output))
    model.add(Activation("softmax"))

    model.compile(loss='mse', optimizer='adadelta')
    
    model.fit(X_train, Y_train, batch_size=batch_size, show_accuracy=True,
              nb_epoch=nb_epoch) # , nb_epoch=5, batch_size=32)
    

    loss,accuracy  = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=verbose)
    print "loss=", loss, " accuracy=",  accuracy 

    print "evaluating with test data----------\n"
    prediction = model.predict(X_test)
    e_test=Evaluation(X_test, Y_test, prediction, learn)
    e_test.stats()

    print "evaluating with training data----------\n"
    loss,accuracy  = model.evaluate(X_train, Y_train, show_accuracy=True, verbose=verbose)
    print "loss=", loss, " accuracy=",  accuracy 
    prediction= model.predict(X_train)
    e_training= Evaluation(X_train, Y_train, prediction, learn)
    s_training= e_training.stats()
                
        
# adadelta, rmsprop, sgd
# classification anstatt linear
# softmax 
