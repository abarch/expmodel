import sys
import optparse
import os
import numpy as np
from compiler.ast import flatten

#sklearn imports
from sklearn import preprocessing
from sklearn.cross_validation import train_test_split   

#local imports 
from features import parseFile
#from features import composeFeatures 


#keras imports 
from keras.models import Sequential
from keras.layers.core import Dense, Activation

NB_CLASSES=16

class Evaluation:

    def __init__(self, X_test, Y_test, prediction):
        # input variables 
        self.x=X_test
        self.y=Y_test
        self.p=prediction

        self.r=NB_CLASSES

        # stats variables 
        self.action1=0.0 
        self.action2=0.0
        self.hand1=0.0 
        self.hand2=0.0
        self.overall1=0.0 
        self.overall2=0.0

    # find first max index in a list of outputs generated by NN     
    def firstmax_index (self, ll):
        return ll.index(max(ll))
        
    # find second max index in a list of outputs generated by NN
    def secondmax_index (self, ll):
        s =  sorted(ll, reverse=True)
        return ll.index(s[1])

    # def compi (self, l, fun):
    # return 1 if l[fun(*l)]== 
    def classequals(self, label, pred):
        label = list(label)
        pred = list(pred)

        pred_action=pred[0:self.r]
        pred_hand  =pred[self.r:]

        label_action=label[0:self.r]
        label_hand = pred[self.r:]
        
        action_firstmax = 1 \
        if self.firstmax_index(pred_action)== label_action.index(max(label_action)) else 0
        action_secondmax = 1 \
        if self.secondmax_index(pred_action)== label_action.index(max(label_action)) else 0
        hand_firstmax = 1 \
        if self.firstmax_index(pred_hand)==label_hand.index(max(label_hand)) else 0
        hand_secondmax = 1 \
        if self.firstmax_index(pred_hand)==label_hand.index(max(label_hand)) else 0 
        
        return action_firstmax, action_secondmax, hand_firstmax, hand_secondmax
       

    def stats(self):
        overall=len(self.x)
        for i in range(overall):
            a1, a2, h1, h2 = self.classequals(self.y[i],self.p[i])
            self.action1+=a1
            self.action2+=a2
            self.hand1+=h1
            self.hand2+=h2
            if (a1 and h1): self.overall1+=1
            if (a2 and h2): self.overall2+=1  
            
        self.print_stat()

    def print_stat(self):
        length = float(len (self.x))
        print "length of data=", length,  " action1=", self.action1,  ", action2=", self.action2, ", hand1=", self.hand1,  \
        " hand2=", self.hand2, " OVERALL1=", self.overall1, " OVERALL2=", self.overall2 
        l = [self.action1, self.action2, self.hand1, self.hand2, self.overall1, self.overall2]
        
        l = map (lambda x: x/length, l)
        print "list of ratios",  l 

def composeFeatures (distances, fingers,hand,labels, learn=[1,2,3,4,5]):
    def empty(featurevec):
        if ('' in featurevec ) or (' ' in featurevec):
            return True
    def equal_ts(tss): 
        tss= map (int, tss)
        return all(x==tss[0] for x in tss)
    def get_ts(vec):
        return vec[0]
    def get_feature(vec):
        return vec[1]
    # large label vector    
    def labelFingers():
        nb_labels = NB_CLASSES
        nb_fingers = max(learn)
        zeros = np.zeros([nb_fingers+1, nb_labels]) 
        for (i, label) in enumerate(labeli):
            zeros[0,label]=1
            zeros[i,label]=1
        #return zeros
        return zeros.flatten().tolist()

            
    alldata=[]
    labeling=[]
    unpr= len(distances)
    print "complete data length", unpr
    for i  in range(unpr):

        di=distances[i]
        vfi=fingers[i]
        vhi=hand[i]
        labeli = labels[i]

        if equal_ts(map(get_ts, [vfi,vhi, labeli])):
            features= map (get_feature, [di, vfi,vhi])
            if not (True in  map (empty, features)):
                features= flatten (features)
                labeli= get_feature(labeli)
                labeli = map( int, labeli)
                labeli = labelFingers() #sparseLabels()  #labelFingers().flatten().tolist()
                labeling += [labeli]
                alldata +=[map(float, features)]
    
    
    X = np.array(alldata)
    Y = np.array(labeling)
    return X,Y 
    

    
  
      


if __name__ == "__main__":
    parser = optparse.OptionParser(usage = 'usage: %prog [OPTIONS]')
    parser.add_option('--handv-file', 
                      dest    = 'handv_file',
                      default = 'handvelocity.txt')
    parser.add_option('--fingerv-file', 
                      dest    = 'fingerv_file',
                      default = 'fingervelocity.txt')
    parser.add_option('--distance-file', 
                      dest    = 'distance_file',
                      default = 'smootheddistances.txt')
    parser.add_option('--board-annotation-file',
                      dest = 'board_annotation_file',
                      default = 'annotation2D.txt')
    parser.add_option('--label-annotation-file',
                      dest = 'label_annotation_file',
                      default = 'labels_25ms.csv')
    parser.add_option('--input-dir',
                      dest  = 'input_dir',
                      default = '/homes/abarch/hapticexp/code/expmodel/featuredata')
    parser.add_option('--nb-epoches', 
                      dest = 'nb_epoches',
                      type = "int",
                      default = 1)
    parser.add_option('--hidden-units',
                      dest = 'hidden_units',
                      type = "int",
                      default = 500) 
    (options, args) = parser.parse_args(sys.argv)
    
    # data extraction parameters  
    board = [1,1]



    # reading data from files
    board_annotation_file=os.path.join(options.input_dir, 
                                       options.board_annotation_file)
    distances= parseFile(os.path.join(options.input_dir, 
                                      options.distance_file),  
                         board_annotation_file, board, range(2,12)) 
    fingers= parseFile(os.path.join(options.input_dir, 
                                    options.fingerv_file), 
                       board_annotation_file, board, range(1,11))
    hand =  parseFile(os.path.join(options.input_dir, options.handv_file), 
                      board_annotation_file, board, range(1,4))
    labels = parseFile(os.path.join(options.input_dir, 
                                    options.label_annotation_file), 
                       board_annotation_file, board, range(2, 7))
  
    # put data togeather with its labels
    X,Y = composeFeatures(distances,fingers,hand,labels)

    print X.shape
    print Y.shape
    

    #preprocessing
    #scaler to 1 variance
    scaler = preprocessing.StandardScaler(with_mean=False)
    X=scaler.fit_transform(X)

    
    test_size = 0.2
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, 
                                                        test_size=test_size,
                                                        random_state=0)
        
    verbose = 0 
    batch_size =  32
    nb_epoch=options.nb_epoches
    dim_input = X.shape[1]
    dim_output = Y.shape[1]
    hidden_layer = options.hidden_units 
                    

    model = Sequential()          
    model.add(Dense(input_dim=dim_input, output_dim=hidden_layer))
    model.add(Activation("sigmoid"))
    model.add(Dense(input_dim=hidden_layer, output_dim=dim_output))
    model.add(Activation("softmax"))

    model.compile(loss='mse', optimizer='adadelta')
    
    model.fit(X_train, Y_train, batch_size=batch_size, show_accuracy=True,
              nb_epoch=nb_epoch) # , nb_epoch=5, batch_size=32)
    

    loss,accuracy  = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=verbose)
    print "loss=", loss, " accuracy=",  accuracy 

    print "evaluating with test data----------\n"
    prediction = model.predict(X_test)
    e_test=Evaluation(X_test, Y_test, prediction)
    e_test.stats()

    print "evaluating with training data----------\n"
    loss,accuracy  = model.evaluate(X_train, Y_train, show_accuracy=True, verbose=verbose)
    print "loss=", loss, " accuracy=",  accuracy 
    prediction= model.predict(X_train)
    e_training= Evaluation(X_train, Y_train, prediction)
    s_training= e_training.stats()
                
        
# adadelta, rmsprop, sgd
# classification anstatt linear
# softmax 
